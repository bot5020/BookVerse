import asyncio
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from aiogram import Bot, Dispatcher, types, F
from aiogram.filters import Command
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from aiogram.fsm.storage.memory import MemoryStorage
from aiogram.types import InlineKeyboardButton, InlineKeyboardMarkup

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
API_TOKEN = "YOUR_TELEGRAM_BOT_TOKEN"
bot = Bot(token=API_TOKEN)
storage = MemoryStorage()
dp = Dispatcher(storage=storage)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞
model_name = "Qwen/Qwen2.5-3B-Instruct"
model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype="auto", device_map="auto")
tokenizer = AutoTokenizer.from_pretrained(model_name)

# –°–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è FSM
class SummarizationStates(StatesGroup):
    waiting_for_text = State()
    waiting_for_level = State()

# –§—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∑—é–º–µ
def generate_summary(text, level="weak"):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∑—é–º–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è —Å–∂–∞—Ç–∏—è.

    :param text: –¢–µ–∫—Å—Ç –¥–ª—è —Å–∂–∞—Ç–∏—è
    :param level: –£—Ä–æ–≤–µ–Ω—å —Å–∂–∞—Ç–∏—è (strong –∏–ª–∏ weak)
    :return: –°–∂–∞—Ç—ã–π —Ç–µ–∫—Å—Ç
    """
    
    system_prompt = "–¢—ã –±–æ—Ç –∫–æ—Ç–æ—Ä—ã–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ–Ω—è—Ç–Ω–æ –∏–∑–ª–∞–≥–∞–µ—Ç —Ç–µ–∫—Å—Ç. –í–∞–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –æ—Å–Ω–æ–≤–Ω—É—é –º—ã—Å–ª—å –∏ —Å–æ—Ö—Ä–∞—è—Ç—å –∫–ª—é—á–µ–≤—ã–µ –¥–µ—Ç–∞–ª–∏ –∏ —Å–æ–±—ã—Ç–∏—è."
    user_prompt = (
        f"–ü—Ä–æ—á–∏—Ç–∞–π —Ç–µ–∫—Å—Ç –∏ –ø–µ—Ä–µ–¥–∞–π –æ—Å–Ω–æ–≤–Ω—É—é –º—ã—Å–ª—å. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π.\n\n–¢–µ–∫—Å—Ç:\n{text}"
        if level == "strong"
        else f"–ü—Ä–æ—á–∏—Ç–∞–π —Ç–µ–∫—Å—Ç –∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —Å–æ–∫—Ä–∞—Ç–∏ –µ–≥–æ –¥–æ 1 –∫—Ä–∞—Ç–∫–æ–≥–æ –∞–±–∑–∞—Ü–∞, —Å–æ—Ö—Ä–∞–Ω—è—è –∫–ª—é—á–µ–≤—ã–µ –¥–µ—Ç–∞–ª–∏ –∏ —Å–æ–±—ã—Ç–∏—è.\n\n–¢–µ–∫—Å—Ç:\n{text}"
    )
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}]
    
    model_input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    model_inputs = tokenizer([model_input_text], return_tensors="pt").to(model.device)

    generated_ids = model.generate(**model_inputs, max_new_tokens=512)
    generated_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]
    
    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
    return response

# –ö–ª–∞–≤–∏–∞—Ç—É—Ä—ã
compression_keyboard = InlineKeyboardMarkup(
    inline_keyboard=[
        [InlineKeyboardButton(text="–°–∏–ª—å–Ω–æ–µ —Å–∂–∞—Ç–∏–µ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)", callback_data="strong")],
        [InlineKeyboardButton(text="–°–ª–∞–±–æ–µ —Å–∂–∞—Ç–∏–µ (–∫—Ä–∞—Ç–∫–∏–π –∞–±–∑–∞—Ü)", callback_data="weak")]
    ]
)

new_text_keyboard = InlineKeyboardMarkup(
    inline_keyboard=[
        [InlineKeyboardButton(text="–ó–∞–≥—Ä—É–∑–∏—Ç—å –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç", callback_data="new_text")]
    ]
)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start
@dp.message(Command("start"))
async def start_command(message: types.Message, state: FSMContext):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ —Å–∂–∞—Ç—å.")
    await state.set_state(SummarizationStates.waiting_for_text)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
@dp.message(SummarizationStates.waiting_for_text)
async def get_text(message: types.Message, state: FSMContext):
    await state.update_data(text=message.text)
    await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ —É—Ä–æ–≤–µ–Ω—å —Å–∂–∞—Ç–∏—è:", reply_markup=compression_keyboard)
    await state.set_state(SummarizationStates.waiting_for_level)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –≤—ã–±–æ—Ä–∞ —É—Ä–æ–≤–Ω—è —Å–∂–∞—Ç–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∑—é–º–µ
@dp.callback_query(SummarizationStates.waiting_for_level)
async def summarize_text(callback_query: types.CallbackQuery, state: FSMContext):
    await callback_query.answer()  
    
    data = await state.get_data()
    text = data.get("text")

    if not text:
        await callback_query.message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è —Å–∂–∞—Ç–∏—è.")
        await state.set_state(SummarizationStates.waiting_for_text)
        return

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —Å–∂–∞—Ç–∏—è
    level = "strong" if callback_query.data == "strong" else "weak"
    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –∏–¥–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
    await callback_query.message.edit_text("–ì–µ–Ω–µ—Ä–∏—Ä—É—é —Ä–µ–∑—é–º–µ...")

    await bot.send_chat_action(callback_query.from_user.id, action="typing")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∑—é–º–µ
    summary = generate_summary(text, level)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –Ω–æ–≤–æ–π –∫–ª–∞–≤–∏–∞—Ç—É—Ä–æ–π
    await callback_query.message.edit_text(f"üìú –†–µ–∑—é–º–µ:\n\n{summary}", reply_markup=new_text_keyboard)
    
    # –û—á–∏—â–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –Ω–æ–≤–æ–≥–æ –≤–≤–æ–¥–∞
    await state.set_state(SummarizationStates.waiting_for_text)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ–≤–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
@dp.callback_query(F.data == "new_text")
async def new_text_handler(callback_query: types.CallbackQuery, state: FSMContext):
    await callback_query.answer() 
    await callback_query.message.answer("–û—Ç–ø—Ä–∞–≤—å—Ç–µ –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å–∂–∞—Ç–∏—è.")
    await state.set_state(SummarizationStates.waiting_for_text)

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
